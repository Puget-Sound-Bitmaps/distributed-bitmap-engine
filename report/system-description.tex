\section{System Description}
DBIE is designed to run on Linux and its operability has been confirmed on
Ubuntu 16.04.4 LTS. The following sections detail various design choices made
during the implementation of DBIE.
%
\subsection{Client Interface}
Our system's ``client'' is a database management system (DBMS). The DBMS runs
as a separate process from the distributed system and interfaces with our
system through two functions: \code{PUT(k,v)} which adds a single vector
numbered \code{k} with value \code{v} to the system (or replaces the value of
vector \code{k} with \code{v}), and \code{QUERY(q)} which returns the results
of a given query string \code{q} on the index. In production, the DBMS could be
a full-featured product like SQLite, but we created a faux DBMS that provided
fine-grained control for testing.
%
\subsection{System Architecture}
Our system is built using the \term{master-slave model}. There is one
master node to which the DBMS makes \code{PUT} and \code{GET} requests.
Upon receiving a \code{PUT} request, the master sends the vector to
\(r \geq 2\) unique slave nodess where \(r\) stands for the
\term{replication factor} of the system (i.e., the number of replicas of each
piece of data). The vector is saved on \(r\) slaves so that if
one node became inoperative the vectors it held are not lost. In our
implementation we assume that \(r = 2\).
\par
To satisfy a given query, the master node constructs a \term{query plan},
which specifies which slaves will help satisfy the query, and
in what order. The slaves work together to satisfy queries using vectors they
contain, and return partial query results to the master. The master
collates the results from each slave and returns it to the DBMS.
The algorithms by which queries are satisfied are given in later sections.
%
\begin{figure}
    \includegraphics[width=\columnwidth]{system-picture}
    \caption{Visualization of the System Architecture}
    \label{fig:system-visualization}
\end{figure}
%
\subsection{Interprocess Communication}
Distributed systems require additional methods of communication beyond those
used in single-process systems. Communication between nodes was accomplished
using remote procedure calls (RPCs). \cite{rpcgen} An RPC is simply a function
call from one process to another. \cite{tanenbaum1994} RPCs are a method of
simplifying communication between nodes by hiding the networking details and
instead allowing developers to make function calls between nodes. This helps to
make the source code more readable and avoid mistakes in manually opening and
closing network connections. In the current implementation, the master node
resides on the same node as the DBMS. The master and DBMS processes
communicate via message queues. \cite{unixSystemV} Requests are passed as
messages, and the results could be fed into a different queue but are currently
printed to the standard out device.
%
\subsection{Bitmap Compression}
In order to perform the necessary bitmap operations (\code{AND}s and
\code{OR}s), we utilized Chiu et al.'s bitmap engine which was
developed by several students under the direction of David Chiu. The
bitmap engine has three compression and query methods implemented: Byte aligned
Bitmap Code (BBC), Word aligned Hybrid Code (WAH),
and Variable Aligned Length Code (VAL). \cite{guzun2014,wu2001} Each of these
compression and query methods provides substantial benefits over the use of
uncompressed bitmap vectors. Of the three, we chose to use WAH as it has been
shown to be faster than BBC and it has a simpler formatting than VAL. WAH
allows compression of vectors such that all information the vector gives is
encoded, and it allows compressed vectors to be queried. A complete description of WAH
is given by \cite{wu2001}.
%
\subsection{Bitmap Vectors}
The lengths and quantities of bitmap vectors grow proportionally to the size of
the data they index. Slaves save each vector as a file. The vector is broken up
into 64-bit pieces, and each piece is saved sequentially into the file.
%
\subsection{Consistent Hashing}
To determine on which two slaves a given vector is located (or should be
located, if the vector identifier is new to the system) we use an algorithm known as
\term{consistent hashing}. Consistent hashing was introduced by
Karger~et~al.~\cite{karger1997} and can be understood conceptually as follows.
\par
Each slave node is assigned a point on a circle where each point corresponds
to a value between \(0\) and \(2^{64} - 1\). The point for a node with
identifier \(i\) is calculated as
\begin{equation*}
    \func{h}{i} \coloneqq \func{SHA1}{i} \bmod{2^{64}}.
\end{equation*}
To determine which nodes (should) contain the vector \(k\), walk clockwise
from the point \(\func{h}{k}\) until reaching a slave node (the
\term{primary} node), and continue walking until reaching the next node
(the \term{backup} node). Once the primary and backup nodes have been
determined, return the set comprised of those two nodes. This procedure is
represented visually in Figure~\ref{fig:ring-hash-process} and formalized in
Algorithm~\ref{alg:consistent-hashing}.
%
\par
In our system, the consistent hashing structure is maintained as a red-black
tree, and determining the next node is given by the algorithms
\procedure{Tree-Succ} (Algorithm~\ref{alg:tree-succ}) and
\procedure{Recur-Succ} (Algorithm~\ref{alg:recur-succ}
\cite{bstPredecessorSuccessor}). When the system is initialized, each node
is assigned a nonnegative integer as an identifier. Each node of the tree is
associated with a slave in the system, and is identified by the corresponding
slave's id. After the identifiers are assigned, they are inserted into the
tree. Each node has pointers to its left child, right child, and parent
(accessible via the functions \procedure{Left}, \procedure{Right} and
\procedure{Par}, respectively). If a node does not have a parent or a child,
that pointer will hold the value \(null\). The algorithms for
\procedure{Tree-Min} and \procedure{Tree-Max} are given in \cite{cormen2009}.
%
\begin{figure}
    \centering
    \includegraphics{ring-hash}
    \caption{Visualization of Ring Consistent Hashing}
    \label{fig:ring-hash-process}
\end{figure}
%
\begin{figure}
    \centering
    \includegraphics{tree}
    \caption{Red-Black Tree Traversal}
    \label{fig:tree-traversal}
\end{figure}
%
\begin{algorithm}
    \begin{algorithmic}
        \Procedure{Consistent-Hash}{$tree, key$}
            \State $p \gets \Call{Tree-Succ}{tree, \func{h}{key}}$
            \State $b \gets \Call{Tree-Succ}{tree, \func{h}{p.id}}$
            \State \Return $(p, b)$
        \EndProcedure
    \end{algorithmic}
    \caption{Consistent Hashing}
    \label{alg:consistent-hashing}
\end{algorithm}
%
\begin{algorithm}
    \begin{algorithmic}
        \Procedure{Tree-Succ}{$tree, key$}
            \If{$\func{h}{key} \geq \func{h}{\Call{Tree-Max}{tree}.id}$}
                \State \Return \Call{Tree-Min}{$tree$}
            \Else
                \State $root \gets \Call{Root}{tree}$
                \State \Return \Call{Recur-Succ}{$tree, root, root, key$}
            \EndIf
        \EndProcedure
    \end{algorithmic}
    \caption{Successor Node}
    \label{alg:tree-succ}
\end{algorithm}
%
\begin{algorithm}
    \begin{algorithmic}
        \Procedure{Recur-Succ}{$tree, root, succ, key$}
            \If{$root = null$}
                \State \Return $succ$
            \ElsIf{$key = \func{h}{root.id}$}
                \If{$\Call{Right}{root} = null$}
                    \While{$\Call{Par}{succ} \neq null \land \func{h}{succ} < key$}
                        \State $succ \gets \Call{Par}{succ}$
                    \EndWhile
                \Else
                    \State $succ \gets \Call{Right}{root}$
                    \While{$\Call{Left}{succ} \neq null$}
                        \State $succ \gets \Call{Left}{succ}$
                    \EndWhile
                \EndIf
                \Return {$succ$}
            \ElsIf{$\func{h}{root.id} > key$}
                \State $left \gets \Call{Left}{root}$
                \State \Return \Call{Recur-Succ}{$tree, left, root, key$}
            \Else
                \State $right \gets \Call{Right}{root}$
                \State \Return \Call{Recur-Succ}{$tree, right, succ, key$}
            \EndIf
        \EndProcedure
    \end{algorithmic}
    \caption{Recursively Determined Successor Node}
    \label{alg:recur-succ}
\end{algorithm}
%
\subsection{Two-Phase Commit}
After we had decided on a method for determining \emph{where} to store data,
we needed a method of ensuring that the data actually arrived at the
appropriate slaves. To do this, we used the Two-Phase Commit protocol (2PC).
Before committing a vector to a slave, the master checks that both slaves are
available: if so, the vector is sent to both, if either is unavailable, the
inaccessible slave is removed from the system and the commit of the vector is
restarted. \cite{tanenbaum2017}
%
\subsection{Fault Tolerance}
The primary reason for using consistent hashing is for fault tolerance. While
waiting for messages from the DBMS, the master checks the status of its slaves
by pinging each. If it does not hear back from a slave after a
reasonable length of time (one second in our system), it assumes that the slave
is out of commission, and reallocates the slave's vectors using \procedure{Reallocate}
(Algorithm~\ref{alg:reallocate}). In each node in the tree we store the
identifiers of the vectors on the associated slave, specifically for this
purpose.
\par
An example of this procedure can be seen in Figure~\ref{fig:vector-reallocation}. There,
node \(F\) has failed, and the master had determined that vectors must be
reallocated. The vectors that must be reallocated are those for which \(F\) was
the primary location and those for which \(F\) was the backup location. First,
vectors \(v_1\) and \(v_2\) had \(F\) as their primary location and \(B\) as
their backup location (which will now become their primary location). So, \(B\)
will send (in one message) copies of \(v_1\) and \(v_2\) to node \(C\) which
will serve as the new backup location. Second, vectors \(v_4\) and \(v_5\) will
be sent (in one message) from \(A\) (their primary location) to \(B\) which
will take over as backup for \(F\). After this, the system will once again
contain two copies of each vector.
\par
%
In our implementation we utilized algorithms provided by \cite{cormen2009}
to find the predecessor of a slave (\procedure{Tree-Pred}), to find the
successor of a slave (\procedure{Tree-Succ}), and to delete a slave from the
tree (\procedure{RB-Delete}). We also made use of an RPC,
\(\func{\procedure{Send-Vector}}{s_1, k, s_2}\),
that we wrote which makes slave \(s_1\) send the vector \(k\) to slave \(s_2\).
\par
Using consistent hashing, we know that the failed slave's backup vectors are
the primary vectors of its predecessor. The successor must now maintain copies
of the predecessor's vectors, so the master notifies the predecessor to
communicate its primary vectors to the successor. Likewise, since the successor
node now holds the slave's primary vectors alongside its own, it must send the
slave's primary vectors to its successor as a backup.
\par
Consistent hashing is preferable to using a hash-mod-n algorithm,
whose hash function modulus is the number of nodes. When the system changes
while using the hash-mod-n algorithm, it is possible that every single vector
would have to be remapped. This remapping requires significantly more message
passing than the \procedure{Reallocate} function. This is because
when a slave node is removed while using the hash-mod-n technique, the primary
location of every vector has the potential to change, thus requiring the system to remap every
single vector in the worst case. \cite{kleppmann2017} While hash-mod-n requires
\(\func{O}{K}\) remappings, where \(K\) is the number of vector identifiers, consistent
hashing only requires \(\func{O}{K/n}\) remappings where \(n\) is the number of
slaves. \cite{karger1997}
%
\begin{figure}
    \centering
    \includegraphics{reallocate}
    \caption{Visualization of Vector Reallocation}
    \label{fig:vector-reallocation}
\end{figure}
%
\begin{algorithm}
    \begin{algorithmic}
        \Procedure{Reallocate}{$tree, slave$}
            \State $pred \gets \Call{Tree-Pred}{tree, slave}$
            \State $succ \gets \Call{Tree-Succ}{tree, slave}$
            \State $ssucc \gets \Call{Tree-Succ}{tree, succ}$
            \ForAll{$v \in (slave.vectors \cap succ.vectors)$}
                \State \Call{Send-Vector}{$succ, v, ssucc$}
            \EndFor
            \ForAll{$w \in (slave.vectors \cap pred.vectors)$}
                \State \Call{Send-Vector}{$pred, w, succ$}
            \EndFor
            \State \Call{RB-Delete}{$tree, slave$}
        \EndProcedure
    \end{algorithmic}
    \caption{Reallocation}
    \label{alg:reallocate}
\end{algorithm}
%
\subsection{Queries}
Our system is designed to handle \term{range queries}. In this context, a range
query is a query written as a number of ranges which are \code{AND}ed together.
Each range is given as a pair of vector identifiers specifying the first and
last vector in the range. Within these ranges, the vectors are \code{OR}ed
together. An example of a range query is \code{R:[2,3]\&[4,6]} which would,
in the context of Tables~\ref{table:census-salary} and \ref{table:census-age},
correspond to the SQL query
\code{SELECT * FROM CENSUS WHERE SALARY~>~\$100000 AND AGE~<~50} given in the introduction.
Using the bitmap index, the query can be satisfied by evaluating the expression
\((v_2 \lor v_3) \land (v_4 \lor v_5 \lor v_6)\).
To carry out a query, we first create a plan that tells us which slave nodes
contain the requisite vectors, and then perform that query.
%
\subsection{Query Planning}
Our query planning algorithm (Algorithm~\ref{alg:query-planning}) takes three
inputs. The first input, \(tree\), is the red-black tree used in consistent
hashing to determine which two nodes contain a given vector identifier, and the
second input, \(r\), is the replication factor of the system.
The third input,
\(R\),
is a list of pairs where each pair \((i,j)\in R\) represents a range starting at
\(v_i\) and ending at \(v_j\), where \(i\leq j\). Sorting of \(subpaths\) is performed so that, in each
portion of the query, slaves do not have to be visited more than once, making
query processing linear with respect to the number of slaves. Because
\(\lor\) is commutative, the order in which the vectors are \code{OR}ed
together within the subquery does not matter. Each range of the query may be
run concurrently. In an effort to distribute the work to all slaves as evenly
as possible, we choose a random return value from \procedure{Consistent-Hash}
as the slave to visit for each of the given vectors. This selection is
determined using the \procedure{Random} function which takes two integer
arguments, \(a\) and \(b\), and returns a random integer in the range
\([a, b)\).
\par
The return value of \procedure{Range-Query-Plan} is a set of \term{subqueries},
\(Q\), where each subquery comprises one or more pairs of the form
\(\tuple{slave\_id,vector\_id}\). These pairs are used in the query execution
algorithms to determine which slaves to visit and which vectors to obtain. For
example, the pair \(\tuple{3, 2}\) indicates that \(v_2\) should be retrieved
from slave 3.
%
\begin{algorithm}
    \begin{algorithmic}
        \Procedure{Range-Query-Plan}{$tree, r, R$}
            \State $paths \gets \emptyset$
            \ForAll{$(first, last) \in R$}
                \State $subpaths \gets \emptyset$
                \For{$k \in [first, last]$}
                    \State $nodes \gets \Call{Consistent-Hash}{tree, k}$
                    \State $node \gets nodes[\Call{Random}{0, r}]$
                    \State $subpaths \gets subpaths \cup \set{(node, k)}$
                \EndFor
                \State Sort $subpaths$ on $node$
                \State $paths \gets paths \cup \set{subpaths}$
            \EndFor
            \Return $paths$
        \EndProcedure
    \end{algorithmic}
    \caption{Query Planning}
    \label{alg:query-planning}
\end{algorithm}
%
\subsection{Query Execution}
Execution of queries received by the master is handled using
Algorithm~\ref{alg:master-query-root} which first plans out the query using
Algorithm~\ref{alg:query-planning} and then delegates each subquery to its
slaves using Algorithm~\ref{alg:slave-subquery}.
\par
Algorithm~\ref{alg:slave-subquery} is an RPC that takes a node identifier,
denoting the slave that the function is run on, and a set of pairs
representing a subquery. The slave iterates over the pairs referencing vectors
it contains, and \code{OR}s the vectors together using WAH, as denoted by \(\lor\).
\(\func{\procedure{Retrieve-Vector}}{k}\) returns the value of vector \(v_k\).
Once the slave has operated on all requested vectors it holds, it makes an RPC
to the slave in the subsequent pair, recursively satisfying the remainder of
the subquery.
\par
Algorithm~\ref{alg:master-query-root} takes a complete query, divides the work
among the slaves, \code{AND}s the results of the subqueries (denoted by
\(R\)) together, and returns the result to the DBMS.
%
\begin{algorithm}
    \begin{algorithmic}
        \Procedure{Master-Query-Root}{$Q$}
            \State $R \gets \emptyset$
            \ForAll{$subquery \in Q$}
                \Comment{Delegate subqueries.}
                \State $slave\_id \gets subquery[0][0]$
                \State $r \gets \Call{Range-SubQuery}{slave\_id, subquery}$
                \State $R \gets R \cup \set{r}$
            \EndFor
            \State $v \gets \vec{1}$
            \ForAll{$w \in R$}
                \Comment{\code{AND} the results.}
                \State $v \gets v \land w$
            \EndFor
            \State \Return $v$
        \EndProcedure
    \end{algorithmic}
    \caption{Master Query Root}
    \label{alg:master-query-root}
\end{algorithm}
%
\begin{algorithm}
    \begin{algorithmic}
        \Procedure{Range-SubQuery}{$node\_id, subquery$}
            \State $r \gets \vec{0}$
            \ForAll{$(node, vec) \in subquery$}
                \If{$node = node\_id$} \Comment{Vector on current node.}
                    \State $r \gets r \lor \Call{Retrieve-Vector}{vec}$
                    \State $subquery \gets subquery \setminus (node, vec)$
                \Else \Comment{Make RPC to next node.}
                    \State $s \gets \Call{Range-SubQuery}{node, subquery}$
                    \State $r \gets r \lor s$
                \EndIf
            \EndFor
            \State \Return $r$
        \EndProcedure
    \end{algorithmic}
    \caption{Slave subquery}
    \label{alg:slave-subquery}
\end{algorithm}
%
\subsection{Implementation and Testing Notes}
DBIE was primarily written in the C programming language due to its speed and
common usage in systems programming. Python~3 was used to script the production
of testing data, which we obtained from the TPC-C data repository \cite{tpcc}.
Python~3 was also used in collaboration with bash to produce startup scripts
that facilitated automatic testing of the system. In order to create our RPCs,
we had to specify the types of RPCs being used in the ONC+ RPC language
\cite{stevens1999} which is an extension of the eXternal Data Representation
(XDR) language developed in the mid 1980s by Sun Microsystems \cite{rpcgen}.
